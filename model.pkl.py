# -*- coding: utf-8 -*-
"""project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LvElPz-nTMWslG5vdGXyq6qBrlx5Z85k
"""

import pandas as pd
import csv
csv.field_size_limit(1000000)
df = pd.read_csv('WELFake_Dataset.csv', engine='python')
print(df.head())
print(df.columns)

print(df['label'].value_counts())
print(df.isnull().sum())

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def clean_text(text):
    if isinstance(text, float):
        text = ""
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'\W', ' ', text)
    text = text.lower()
    text = text.split()
    text = [stemmer.stem(word) for word in text if word not in stop_words]
    return " ".join(text)
df['cleaned_text'] = (df['text'].fillna('') + ' ' + df['title'].fillna('')).apply(clean_text)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=10000)
X = vectorizer.fit_transform(df['cleaned_text'])
y = df['label']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

!pip install streamlit

import pickle
with open("model.pkl", "wb") as file:
    pickle.dump(model, file)

with open("vectorizer.pkl", "wb") as file:
    pickle.dump(vectorizer, file)

import pickle
pickle.dump(model, open("model.pkl", "wb"))
from google.colab import files
files.download("model.pkl")